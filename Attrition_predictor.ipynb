{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "a25217a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMPID</th>\n",
       "      <th>Leaver(Y/N)</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race_Ethnicity</th>\n",
       "      <th>Job_Level</th>\n",
       "      <th>Annual_Salary</th>\n",
       "      <th>Position</th>\n",
       "      <th>CurrentPayGrade</th>\n",
       "      <th>TimewithCompany(yrs)</th>\n",
       "      <th>DistancetoWork(miles)</th>\n",
       "      <th>Hybrid/Remote</th>\n",
       "      <th>Dept_Name</th>\n",
       "      <th>Status</th>\n",
       "      <th>Salary_Max%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0ZU</td>\n",
       "      <td>No</td>\n",
       "      <td>35</td>\n",
       "      <td>Female</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Administrative Support Workers</td>\n",
       "      <td>20.8</td>\n",
       "      <td>Benefits and Payroll Coordinator</td>\n",
       "      <td>11</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Remote</td>\n",
       "      <td>HR</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0YO</td>\n",
       "      <td>Yes</td>\n",
       "      <td>31</td>\n",
       "      <td>Female</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>First/Mid-Level Officials and Managers</td>\n",
       "      <td>20.8</td>\n",
       "      <td>Camp Director</td>\n",
       "      <td>7</td>\n",
       "      <td>0.92</td>\n",
       "      <td>45.21</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Outdoor Education</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A03Y</td>\n",
       "      <td>Yes</td>\n",
       "      <td>63</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Laborers and Helpers</td>\n",
       "      <td>9,547.20</td>\n",
       "      <td>Guest Services and Maintenance Specialist - PT</td>\n",
       "      <td>13</td>\n",
       "      <td>3.58</td>\n",
       "      <td>41.49</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Risk and Facilities</td>\n",
       "      <td>Part Time</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A13D</td>\n",
       "      <td>Yes</td>\n",
       "      <td>29</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Sales Workers</td>\n",
       "      <td>10,400.00</td>\n",
       "      <td>Customer Service Representative - PT</td>\n",
       "      <td>13</td>\n",
       "      <td>1.25</td>\n",
       "      <td>21.94</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Badge &amp; Sash</td>\n",
       "      <td>Part Time</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1FN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>33</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Sales Workers</td>\n",
       "      <td>10,400.00</td>\n",
       "      <td>Customer Service Representative - PT</td>\n",
       "      <td>13</td>\n",
       "      <td>7.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Badge &amp; Sash</td>\n",
       "      <td>Part Time</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EMPID Leaver(Y/N)  Age   Gender              Race_Ethnicity  \\\n",
       "0   A0ZU          No   35   Female                 Unspecified   \n",
       "1   A0YO         Yes   31   Female                 Unspecified   \n",
       "2   A03Y         Yes   63     Male   Black or African American   \n",
       "3   A13D         Yes   29   Female                       White   \n",
       "4   A1FN         Yes   33   Female   Black or African American   \n",
       "\n",
       "                                 Job_Level Annual_Salary  \\\n",
       "0           Administrative Support Workers          20.8   \n",
       "1   First/Mid-Level Officials and Managers          20.8   \n",
       "2                     Laborers and Helpers      9,547.20   \n",
       "3                            Sales Workers     10,400.00   \n",
       "4                            Sales Workers     10,400.00   \n",
       "\n",
       "                                          Position  CurrentPayGrade  \\\n",
       "0                 Benefits and Payroll Coordinator               11   \n",
       "1                                    Camp Director                7   \n",
       "2   Guest Services and Maintenance Specialist - PT               13   \n",
       "3             Customer Service Representative - PT               13   \n",
       "4             Customer Service Representative - PT               13   \n",
       "\n",
       "   TimewithCompany(yrs)  DistancetoWork(miles) Hybrid/Remote  \\\n",
       "0                  0.33                   0.00        Remote   \n",
       "1                  0.92                  45.21        Hybrid   \n",
       "2                  3.58                  41.49        Hybrid   \n",
       "3                  1.25                  21.94        Hybrid   \n",
       "4                  7.50                   0.00        Remote   \n",
       "\n",
       "             Dept_Name      Status  Salary_Max%  \n",
       "0                   HR   Full Time         0.00  \n",
       "1    Outdoor Education   Full Time         0.00  \n",
       "2  Risk and Facilities   Part Time         0.21  \n",
       "3         Badge & Sash   Part Time         0.23  \n",
       "4         Badge & Sash   Part Time         0.23  "
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "application_df = pd.read_csv(\"Employee_Attrition.csv\",index_col=[0])\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "4f95d48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMPID</th>\n",
       "      <th>Leaver(Y/N)</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race_Ethnicity</th>\n",
       "      <th>Job_Level</th>\n",
       "      <th>Annual_Salary</th>\n",
       "      <th>Position</th>\n",
       "      <th>CurrentPayGrade</th>\n",
       "      <th>TimewithCompany(yrs)</th>\n",
       "      <th>DistancetoWork(miles)</th>\n",
       "      <th>Hybrid/Remote</th>\n",
       "      <th>Dept_Name</th>\n",
       "      <th>Status</th>\n",
       "      <th>Salary_Max%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0ZU</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>Female</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Administrative Support Workers</td>\n",
       "      <td>20.8</td>\n",
       "      <td>Benefits and Payroll Coordinator</td>\n",
       "      <td>11</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Remote</td>\n",
       "      <td>HR</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0YO</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>Female</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>First/Mid-Level Officials and Managers</td>\n",
       "      <td>20.8</td>\n",
       "      <td>Camp Director</td>\n",
       "      <td>7</td>\n",
       "      <td>0.92</td>\n",
       "      <td>45.21</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Outdoor Education</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A03Y</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Laborers and Helpers</td>\n",
       "      <td>9,547.20</td>\n",
       "      <td>Guest Services and Maintenance Specialist - PT</td>\n",
       "      <td>13</td>\n",
       "      <td>3.58</td>\n",
       "      <td>41.49</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Risk and Facilities</td>\n",
       "      <td>Part Time</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A13D</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Sales Workers</td>\n",
       "      <td>10,400.00</td>\n",
       "      <td>Customer Service Representative - PT</td>\n",
       "      <td>13</td>\n",
       "      <td>1.25</td>\n",
       "      <td>21.94</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Badge &amp; Sash</td>\n",
       "      <td>Part Time</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1FN</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Sales Workers</td>\n",
       "      <td>10,400.00</td>\n",
       "      <td>Customer Service Representative - PT</td>\n",
       "      <td>13</td>\n",
       "      <td>7.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Badge &amp; Sash</td>\n",
       "      <td>Part Time</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>A0K8</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Executive/Senior-Level Officials and Managers</td>\n",
       "      <td>118,560.00</td>\n",
       "      <td>Sr Director - Membership</td>\n",
       "      <td>3</td>\n",
       "      <td>7.00</td>\n",
       "      <td>29.31</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Membership</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>A0O9</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Executive/Senior-Level Officials and Managers</td>\n",
       "      <td>136,735.82</td>\n",
       "      <td>Sr Director - Marketing</td>\n",
       "      <td>3</td>\n",
       "      <td>3.33</td>\n",
       "      <td>13.28</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>A0U1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Service Workers</td>\n",
       "      <td>145,600.00</td>\n",
       "      <td>Junior Program Facilitator</td>\n",
       "      <td>0</td>\n",
       "      <td>13.50</td>\n",
       "      <td>91.86</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Program Support</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>A0U4</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Service Workers</td>\n",
       "      <td>145,600.00</td>\n",
       "      <td>Junior Program Facilitator</td>\n",
       "      <td>0</td>\n",
       "      <td>8.17</td>\n",
       "      <td>12.50</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Program Support</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>A0UK</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Service Workers</td>\n",
       "      <td>145,600.00</td>\n",
       "      <td>Junior Program Facilitator</td>\n",
       "      <td>0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>83.93</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Program Support</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     EMPID  Leaver(Y/N)  Age   Gender              Race_Ethnicity  \\\n",
       "0     A0ZU            0   35   Female                 Unspecified   \n",
       "1     A0YO            1   31   Female                 Unspecified   \n",
       "2     A03Y            1   63     Male   Black or African American   \n",
       "3     A13D            1   29   Female                       White   \n",
       "4     A1FN            1   33   Female   Black or African American   \n",
       "..     ...          ...  ...      ...                         ...   \n",
       "359   A0K8            0   56   Female   Black or African American   \n",
       "360   A0O9            0   49     Male                       White   \n",
       "361   A0U1            1   23   Female                       White   \n",
       "362   A0U4            1   24   Female                       White   \n",
       "363   A0UK            1   23   Female                       White   \n",
       "\n",
       "                                          Job_Level Annual_Salary  \\\n",
       "0                    Administrative Support Workers          20.8   \n",
       "1            First/Mid-Level Officials and Managers          20.8   \n",
       "2                              Laborers and Helpers      9,547.20   \n",
       "3                                     Sales Workers     10,400.00   \n",
       "4                                     Sales Workers     10,400.00   \n",
       "..                                              ...           ...   \n",
       "359   Executive/Senior-Level Officials and Managers    118,560.00   \n",
       "360   Executive/Senior-Level Officials and Managers    136,735.82   \n",
       "361                                 Service Workers    145,600.00   \n",
       "362                                 Service Workers    145,600.00   \n",
       "363                                 Service Workers    145,600.00   \n",
       "\n",
       "                                            Position  CurrentPayGrade  \\\n",
       "0                   Benefits and Payroll Coordinator               11   \n",
       "1                                      Camp Director                7   \n",
       "2     Guest Services and Maintenance Specialist - PT               13   \n",
       "3               Customer Service Representative - PT               13   \n",
       "4               Customer Service Representative - PT               13   \n",
       "..                                               ...              ...   \n",
       "359                         Sr Director - Membership                3   \n",
       "360                          Sr Director - Marketing                3   \n",
       "361                       Junior Program Facilitator                0   \n",
       "362                       Junior Program Facilitator                0   \n",
       "363                       Junior Program Facilitator                0   \n",
       "\n",
       "     TimewithCompany(yrs)  DistancetoWork(miles) Hybrid/Remote  \\\n",
       "0                    0.33                   0.00        Remote   \n",
       "1                    0.92                  45.21        Hybrid   \n",
       "2                    3.58                  41.49        Hybrid   \n",
       "3                    1.25                  21.94        Hybrid   \n",
       "4                    7.50                   0.00        Remote   \n",
       "..                    ...                    ...           ...   \n",
       "359                  7.00                  29.31        Hybrid   \n",
       "360                  3.33                  13.28        Hybrid   \n",
       "361                 13.50                  91.86        Hybrid   \n",
       "362                  8.17                  12.50        Hybrid   \n",
       "363                  0.92                  83.93        Hybrid   \n",
       "\n",
       "               Dept_Name      Status  Salary_Max%  \n",
       "0                     HR   Full Time         0.00  \n",
       "1      Outdoor Education   Full Time         0.00  \n",
       "2    Risk and Facilities   Part Time         0.21  \n",
       "3           Badge & Sash   Part Time         0.23  \n",
       "4           Badge & Sash   Part Time         0.23  \n",
       "..                   ...         ...          ...  \n",
       "359           Membership   Full Time         0.80  \n",
       "360            Marketing   Full Time         0.92  \n",
       "361      Program Support   Full Time         1.00  \n",
       "362      Program Support   Full Time         1.00  \n",
       "363      Program Support   Full Time         1.00  \n",
       "\n",
       "[364 rows x 15 columns]"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_df[\"Leaver(Y/N)\"].replace({\"Yes\": 1, \"No\": 0}, inplace=True)\n",
    "application_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "bde88b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "application_df=application_df.drop(columns=[\"EMPID\",\"Status\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "0b10e757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Leaver(Y/N)                2\n",
       "Age                       51\n",
       "Gender                     3\n",
       "Race_Ethnicity             7\n",
       "Job_Level                  8\n",
       "Annual_Salary            276\n",
       "Position                 143\n",
       "CurrentPayGrade           12\n",
       "TimewithCompany(yrs)     125\n",
       "DistancetoWork(miles)    138\n",
       "Hybrid/Remote              2\n",
       "Dept_Name                 16\n",
       "Salary_Max%               81\n",
       "dtype: int64"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "21fe0042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gender',\n",
       " 'Race_Ethnicity',\n",
       " 'Job_Level',\n",
       " 'Annual_Salary',\n",
       " 'Position',\n",
       " 'Hybrid/Remote',\n",
       " 'Dept_Name']"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cat=application_df.dtypes[application_df.dtypes=='object'].index.tolist()\n",
    "num_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "01000fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Leaver(Y/N)</th>\n",
       "      <th>Age</th>\n",
       "      <th>CurrentPayGrade</th>\n",
       "      <th>TimewithCompany(yrs)</th>\n",
       "      <th>DistancetoWork(miles)</th>\n",
       "      <th>Salary_Max%</th>\n",
       "      <th>Gender_ Female</th>\n",
       "      <th>Gender_ Male</th>\n",
       "      <th>Gender_ Unspecified</th>\n",
       "      <th>Race_Ethnicity_ American Indian or Alaska Native</th>\n",
       "      <th>...</th>\n",
       "      <th>Dept_Name_IT</th>\n",
       "      <th>Dept_Name_Marketing</th>\n",
       "      <th>Dept_Name_Membership</th>\n",
       "      <th>Dept_Name_Mission Delivery</th>\n",
       "      <th>Dept_Name_Outdoor Education</th>\n",
       "      <th>Dept_Name_Outdoor Program</th>\n",
       "      <th>Dept_Name_Outdoor Property</th>\n",
       "      <th>Dept_Name_Product Programs</th>\n",
       "      <th>Dept_Name_Program Support</th>\n",
       "      <th>Dept_Name_Risk and Facilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "      <td>0.92</td>\n",
       "      <td>45.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>13</td>\n",
       "      <td>3.58</td>\n",
       "      <td>41.49</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>13</td>\n",
       "      <td>1.25</td>\n",
       "      <td>21.94</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "      <td>7.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>7.00</td>\n",
       "      <td>29.31</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>3.33</td>\n",
       "      <td>13.28</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>13.50</td>\n",
       "      <td>91.86</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>8.17</td>\n",
       "      <td>12.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>83.93</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 461 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Leaver(Y/N)  Age  CurrentPayGrade  TimewithCompany(yrs)  \\\n",
       "0              0   35               11                  0.33   \n",
       "1              1   31                7                  0.92   \n",
       "2              1   63               13                  3.58   \n",
       "3              1   29               13                  1.25   \n",
       "4              1   33               13                  7.50   \n",
       "..           ...  ...              ...                   ...   \n",
       "359            0   56                3                  7.00   \n",
       "360            0   49                3                  3.33   \n",
       "361            1   23                0                 13.50   \n",
       "362            1   24                0                  8.17   \n",
       "363            1   23                0                  0.92   \n",
       "\n",
       "     DistancetoWork(miles)  Salary_Max%  Gender_ Female  Gender_ Male  \\\n",
       "0                     0.00         0.00               1             0   \n",
       "1                    45.21         0.00               1             0   \n",
       "2                    41.49         0.21               0             1   \n",
       "3                    21.94         0.23               1             0   \n",
       "4                     0.00         0.23               1             0   \n",
       "..                     ...          ...             ...           ...   \n",
       "359                  29.31         0.80               1             0   \n",
       "360                  13.28         0.92               0             1   \n",
       "361                  91.86         1.00               1             0   \n",
       "362                  12.50         1.00               1             0   \n",
       "363                  83.93         1.00               1             0   \n",
       "\n",
       "     Gender_ Unspecified  Race_Ethnicity_ American Indian or Alaska Native  \\\n",
       "0                      0                                                 0   \n",
       "1                      0                                                 0   \n",
       "2                      0                                                 0   \n",
       "3                      0                                                 0   \n",
       "4                      0                                                 0   \n",
       "..                   ...                                               ...   \n",
       "359                    0                                                 0   \n",
       "360                    0                                                 0   \n",
       "361                    0                                                 0   \n",
       "362                    0                                                 0   \n",
       "363                    0                                                 0   \n",
       "\n",
       "     ...  Dept_Name_IT  Dept_Name_Marketing  Dept_Name_Membership  \\\n",
       "0    ...             0                    0                     0   \n",
       "1    ...             0                    0                     0   \n",
       "2    ...             0                    0                     0   \n",
       "3    ...             0                    0                     0   \n",
       "4    ...             0                    0                     0   \n",
       "..   ...           ...                  ...                   ...   \n",
       "359  ...             0                    0                     1   \n",
       "360  ...             0                    1                     0   \n",
       "361  ...             0                    0                     0   \n",
       "362  ...             0                    0                     0   \n",
       "363  ...             0                    0                     0   \n",
       "\n",
       "     Dept_Name_Mission Delivery  Dept_Name_Outdoor Education  \\\n",
       "0                             0                            0   \n",
       "1                             0                            1   \n",
       "2                             0                            0   \n",
       "3                             0                            0   \n",
       "4                             0                            0   \n",
       "..                          ...                          ...   \n",
       "359                           0                            0   \n",
       "360                           0                            0   \n",
       "361                           0                            0   \n",
       "362                           0                            0   \n",
       "363                           0                            0   \n",
       "\n",
       "     Dept_Name_Outdoor Program  Dept_Name_Outdoor Property  \\\n",
       "0                            0                           0   \n",
       "1                            0                           0   \n",
       "2                            0                           0   \n",
       "3                            0                           0   \n",
       "4                            0                           0   \n",
       "..                         ...                         ...   \n",
       "359                          0                           0   \n",
       "360                          0                           0   \n",
       "361                          0                           0   \n",
       "362                          0                           0   \n",
       "363                          0                           0   \n",
       "\n",
       "     Dept_Name_Product Programs  Dept_Name_Program Support  \\\n",
       "0                             0                          0   \n",
       "1                             0                          0   \n",
       "2                             0                          0   \n",
       "3                             0                          0   \n",
       "4                             0                          0   \n",
       "..                          ...                        ...   \n",
       "359                           0                          0   \n",
       "360                           0                          0   \n",
       "361                           0                          1   \n",
       "362                           0                          1   \n",
       "363                           0                          1   \n",
       "\n",
       "     Dept_Name_Risk and Facilities  \n",
       "0                                0  \n",
       "1                                0  \n",
       "2                                1  \n",
       "3                                0  \n",
       "4                                0  \n",
       "..                             ...  \n",
       "359                              0  \n",
       "360                              0  \n",
       "361                              0  \n",
       "362                              0  \n",
       "363                              0  \n",
       "\n",
       "[364 rows x 461 columns]"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_df=pd.get_dummies(application_df)\n",
    "application_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "id": "2cecd875",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the preprocessed data into our features and target arrays\n",
    "#Remove Leaver outcome column target from features data\n",
    "y = application_df[\"Leaver(Y/N)\"].values\n",
    "X = application_df.drop(columns=\"Leaver(Y/N)\").values\n",
    "\n",
    "#Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, random_state=111,test_size = 0.2,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "id": "7765de28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create StandardScaler instances\n",
    "scaler= StandardScaler()\n",
    "\n",
    "#Fit the StandardScaler\n",
    "X_scaler=scaler.fit(X_train)\n",
    "\n",
    "#Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4d2a59",
   "metadata": {},
   "source": [
    "### Compile, Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "id": "0ec93a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_179\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_542 (Dense)            (None, 10)                4610      \n",
      "_________________________________________________________________\n",
      "dense_543 (Dense)            (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_544 (Dense)            (None, 1)                 6         \n",
      "_________________________________________________________________\n",
      "dense_545 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 4,673\n",
      "Trainable params: 4,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Define the model-deep neural net, i.e., the number of input features hidden nodes for each layer\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 10\n",
    "\n",
    "hidden_nodes_layer2 = 5\n",
    "\n",
    "hidden_nodes_layer3 = 1\n",
    "\n",
    "nn= tf.keras.models.Sequential()\n",
    "\n",
    "#First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation =\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "#Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "#Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "id": "715b06c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimize=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "0cab9bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 291 samples\n",
      "Epoch 1/100\n",
      "291/291 [==============================] - 1s 2ms/sample - loss: 0.6993 - accuracy: 0.4674\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 94us/sample - loss: 0.6900 - accuracy: 0.6117\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 97us/sample - loss: 0.6857 - accuracy: 0.6838\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 92us/sample - loss: 0.6823 - accuracy: 0.7251\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 94us/sample - loss: 0.6785 - accuracy: 0.7526\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 108us/sample - loss: 0.6739 - accuracy: 0.7595\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 100us/sample - loss: 0.6686 - accuracy: 0.7835\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 97us/sample - loss: 0.6631 - accuracy: 0.7973\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 98us/sample - loss: 0.6564 - accuracy: 0.8282\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 95us/sample - loss: 0.6495 - accuracy: 0.8385\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 98us/sample - loss: 0.6411 - accuracy: 0.8522\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 91us/sample - loss: 0.6328 - accuracy: 0.8729\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 106us/sample - loss: 0.6245 - accuracy: 0.8797\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 96us/sample - loss: 0.6158 - accuracy: 0.8797\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 89us/sample - loss: 0.6061 - accuracy: 0.8797\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 91us/sample - loss: 0.5974 - accuracy: 0.8866\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 93us/sample - loss: 0.5880 - accuracy: 0.8900\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 94us/sample - loss: 0.5788 - accuracy: 0.8935\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 99us/sample - loss: 0.5686 - accuracy: 0.8935\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 98us/sample - loss: 0.5598 - accuracy: 0.8935\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 92us/sample - loss: 0.5515 - accuracy: 0.8935\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 91us/sample - loss: 0.5436 - accuracy: 0.8935\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 92us/sample - loss: 0.5363 - accuracy: 0.8935\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 89us/sample - loss: 0.5298 - accuracy: 0.9003\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 92us/sample - loss: 0.5225 - accuracy: 0.8969\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 100us/sample - loss: 0.5165 - accuracy: 0.9003\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 92us/sample - loss: 0.5098 - accuracy: 0.9038\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 98us/sample - loss: 0.5029 - accuracy: 0.9038\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 96us/sample - loss: 0.4967 - accuracy: 0.9072\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 94us/sample - loss: 0.4910 - accuracy: 0.9072\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 87us/sample - loss: 0.4861 - accuracy: 0.9175\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 92us/sample - loss: 0.4807 - accuracy: 0.9175\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 92us/sample - loss: 0.4760 - accuracy: 0.9210\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 108us/sample - loss: 0.4709 - accuracy: 0.9244\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 102us/sample - loss: 0.4659 - accuracy: 0.9244\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 97us/sample - loss: 0.4621 - accuracy: 0.9278\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 92us/sample - loss: 0.4582 - accuracy: 0.9313\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 93us/sample - loss: 0.4537 - accuracy: 0.9313\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 99us/sample - loss: 0.4496 - accuracy: 0.9347\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 89us/sample - loss: 0.4458 - accuracy: 0.9347\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 99us/sample - loss: 0.4420 - accuracy: 0.9313\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 98us/sample - loss: 0.4377 - accuracy: 0.9347\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 98us/sample - loss: 0.4342 - accuracy: 0.9347\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 91us/sample - loss: 0.4302 - accuracy: 0.9347\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 98us/sample - loss: 0.4261 - accuracy: 0.9347\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 104us/sample - loss: 0.4224 - accuracy: 0.9347\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 101us/sample - loss: 0.4196 - accuracy: 0.9347\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 90us/sample - loss: 0.4155 - accuracy: 0.9347\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 105us/sample - loss: 0.4129 - accuracy: 0.9347\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 98us/sample - loss: 0.4096 - accuracy: 0.9347\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 97us/sample - loss: 0.4065 - accuracy: 0.9347\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 88us/sample - loss: 0.4038 - accuracy: 0.9347\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.3953 - accuracy: 0.93 - 0s 99us/sample - loss: 0.4007 - accuracy: 0.9347\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 94us/sample - loss: 0.3980 - accuracy: 0.9347\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 87us/sample - loss: 0.3946 - accuracy: 0.9347\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 88us/sample - loss: 0.3924 - accuracy: 0.9347\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 88us/sample - loss: 0.3896 - accuracy: 0.9347\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 87us/sample - loss: 0.3866 - accuracy: 0.9347\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 87us/sample - loss: 0.3854 - accuracy: 0.9347\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 92us/sample - loss: 0.3818 - accuracy: 0.9347\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 89us/sample - loss: 0.3795 - accuracy: 0.9347\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 86us/sample - loss: 0.3769 - accuracy: 0.9347\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 87us/sample - loss: 0.3750 - accuracy: 0.9347\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 89us/sample - loss: 0.3720 - accuracy: 0.9347\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 89us/sample - loss: 0.3695 - accuracy: 0.9347\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 88us/sample - loss: 0.3675 - accuracy: 0.9347\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 95us/sample - loss: 0.3656 - accuracy: 0.9381\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 89us/sample - loss: 0.3631 - accuracy: 0.9381\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 88us/sample - loss: 0.3606 - accuracy: 0.9381\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 92us/sample - loss: 0.3583 - accuracy: 0.9381\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 90us/sample - loss: 0.3562 - accuracy: 0.9381\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 86us/sample - loss: 0.3539 - accuracy: 0.9381\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 90us/sample - loss: 0.3517 - accuracy: 0.9381\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 99us/sample - loss: 0.3507 - accuracy: 0.9381\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 90us/sample - loss: 0.3470 - accuracy: 0.9381\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 96us/sample - loss: 0.3459 - accuracy: 0.9381\n",
      "Epoch 77/100\n",
      "291/291 [==============================] - 0s 88us/sample - loss: 0.3442 - accuracy: 0.9381\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 92us/sample - loss: 0.3422 - accuracy: 0.9381\n",
      "Epoch 79/100\n",
      "291/291 [==============================] - 0s 90us/sample - loss: 0.3403 - accuracy: 0.9381\n",
      "Epoch 80/100\n",
      "291/291 [==============================] - 0s 84us/sample - loss: 0.3372 - accuracy: 0.9381\n",
      "Epoch 81/100\n",
      "291/291 [==============================] - 0s 87us/sample - loss: 0.3364 - accuracy: 0.9381\n",
      "Epoch 82/100\n",
      "291/291 [==============================] - 0s 84us/sample - loss: 0.3341 - accuracy: 0.9381\n",
      "Epoch 83/100\n",
      "291/291 [==============================] - 0s 91us/sample - loss: 0.3332 - accuracy: 0.9381\n",
      "Epoch 84/100\n",
      "291/291 [==============================] - 0s 84us/sample - loss: 0.3305 - accuracy: 0.9416\n",
      "Epoch 85/100\n",
      "291/291 [==============================] - 0s 88us/sample - loss: 0.3288 - accuracy: 0.9381\n",
      "Epoch 86/100\n",
      "291/291 [==============================] - 0s 84us/sample - loss: 0.3262 - accuracy: 0.9381\n",
      "Epoch 87/100\n",
      "291/291 [==============================] - 0s 91us/sample - loss: 0.3247 - accuracy: 0.9381\n",
      "Epoch 88/100\n",
      "291/291 [==============================] - 0s 83us/sample - loss: 0.3227 - accuracy: 0.9381\n",
      "Epoch 89/100\n",
      "291/291 [==============================] - 0s 87us/sample - loss: 0.3212 - accuracy: 0.9381\n",
      "Epoch 90/100\n",
      "291/291 [==============================] - 0s 87us/sample - loss: 0.3195 - accuracy: 0.9381\n",
      "Epoch 91/100\n",
      "291/291 [==============================] - 0s 86us/sample - loss: 0.3172 - accuracy: 0.9381\n",
      "Epoch 92/100\n",
      "291/291 [==============================] - 0s 92us/sample - loss: 0.3159 - accuracy: 0.9381\n",
      "Epoch 93/100\n",
      "291/291 [==============================] - 0s 82us/sample - loss: 0.3134 - accuracy: 0.9381\n",
      "Epoch 94/100\n",
      "291/291 [==============================] - 0s 89us/sample - loss: 0.3132 - accuracy: 0.9381\n",
      "Epoch 95/100\n",
      "291/291 [==============================] - 0s 85us/sample - loss: 0.3105 - accuracy: 0.9416\n",
      "Epoch 96/100\n",
      "291/291 [==============================] - 0s 89us/sample - loss: 0.3095 - accuracy: 0.9381\n",
      "Epoch 97/100\n",
      "291/291 [==============================] - 0s 85us/sample - loss: 0.3074 - accuracy: 0.9381\n",
      "Epoch 98/100\n",
      "291/291 [==============================] - 0s 87us/sample - loss: 0.3063 - accuracy: 0.9416\n",
      "Epoch 99/100\n",
      "291/291 [==============================] - 0s 84us/sample - loss: 0.3046 - accuracy: 0.9416\n",
      "Epoch 100/100\n",
      "291/291 [==============================] - ETA: 0s - loss: 0.4110 - accuracy: 0.84 - 0s 83us/sample - loss: 0.3026 - accuracy: 0.9381\n"
     ]
    }
   ],
   "source": [
    "# #Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "id": "a8cf8d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/1 - 0s - loss: 0.7602 - accuracy: 0.7123\n",
      "Loss: 0.8467095469775265, Accuracy: 0.7123287916183472\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy= nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "id": "0866a06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_216\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_690 (Dense)            (None, 2)                 922       \n",
      "_________________________________________________________________\n",
      "dense_691 (Dense)            (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "dense_692 (Dense)            (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "dense_693 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 937\n",
      "Trainable params: 937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Define the model-deep neural net, i.e., the number of input features hidden nodes for each layer\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 2\n",
    "hidden_nodes_layer2 =3\n",
    "hidden_nodes_layer3 = 1\n",
    "\n",
    "nn= tf.keras.models.Sequential()\n",
    "\n",
    "#First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation =\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "#Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "#Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "id": "c55da087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimize=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "id": "d24a6f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 291 samples\n",
      "Epoch 1/100\n",
      "291/291 [==============================] - 1s 2ms/sample - loss: 0.7620 - accuracy: 0.4983\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 63us/sample - loss: 0.7163 - accuracy: 0.6082\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 58us/sample - loss: 0.6977 - accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 75us/sample - loss: 0.6822 - accuracy: 0.6770\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 76us/sample - loss: 0.6711 - accuracy: 0.7079\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 69us/sample - loss: 0.6605 - accuracy: 0.7320\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 62us/sample - loss: 0.6531 - accuracy: 0.7354\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 63us/sample - loss: 0.6454 - accuracy: 0.7560\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 74us/sample - loss: 0.6390 - accuracy: 0.7732\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 86us/sample - loss: 0.6326 - accuracy: 0.7766\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 57us/sample - loss: 0.6259 - accuracy: 0.7698\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 67us/sample - loss: 0.6194 - accuracy: 0.7904\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 71us/sample - loss: 0.6136 - accuracy: 0.7973\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 78us/sample - loss: 0.6080 - accuracy: 0.8144\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 70us/sample - loss: 0.6028 - accuracy: 0.8179\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 70us/sample - loss: 0.5976 - accuracy: 0.8179\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 70us/sample - loss: 0.5928 - accuracy: 0.8110\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 71us/sample - loss: 0.5874 - accuracy: 0.8247\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 63us/sample - loss: 0.5825 - accuracy: 0.8316\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 68us/sample - loss: 0.5785 - accuracy: 0.8419\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 64us/sample - loss: 0.5743 - accuracy: 0.8454\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 87us/sample - loss: 0.5701 - accuracy: 0.8419\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 64us/sample - loss: 0.5649 - accuracy: 0.8454\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 85us/sample - loss: 0.5614 - accuracy: 0.8454\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 68us/sample - loss: 0.5556 - accuracy: 0.8557\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 62us/sample - loss: 0.5518 - accuracy: 0.8522\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 68us/sample - loss: 0.5466 - accuracy: 0.8729\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 76us/sample - loss: 0.5424 - accuracy: 0.8797\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 68us/sample - loss: 0.5378 - accuracy: 0.8797\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 68us/sample - loss: 0.5340 - accuracy: 0.8866\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 69us/sample - loss: 0.5302 - accuracy: 0.8832\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 70us/sample - loss: 0.5255 - accuracy: 0.8832\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 75us/sample - loss: 0.5224 - accuracy: 0.8866\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 68us/sample - loss: 0.5180 - accuracy: 0.8866\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 77us/sample - loss: 0.5141 - accuracy: 0.8900\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 71us/sample - loss: 0.5103 - accuracy: 0.8866\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 71us/sample - loss: 0.5058 - accuracy: 0.8900\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 57us/sample - loss: 0.5015 - accuracy: 0.8935\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 70us/sample - loss: 0.4981 - accuracy: 0.8935\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 75us/sample - loss: 0.4934 - accuracy: 0.8969\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 78us/sample - loss: 0.4897 - accuracy: 0.9003\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 66us/sample - loss: 0.4868 - accuracy: 0.8969\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 78us/sample - loss: 0.4821 - accuracy: 0.9003\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 77us/sample - loss: 0.4796 - accuracy: 0.9003\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 57us/sample - loss: 0.4748 - accuracy: 0.9038\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 71us/sample - loss: 0.4707 - accuracy: 0.9003\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 82us/sample - loss: 0.4679 - accuracy: 0.8969\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 69us/sample - loss: 0.4642 - accuracy: 0.9003\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 69us/sample - loss: 0.4609 - accuracy: 0.9003\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 65us/sample - loss: 0.4569 - accuracy: 0.9003\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 93us/sample - loss: 0.4531 - accuracy: 0.9003\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 73us/sample - loss: 0.4505 - accuracy: 0.9038\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 71us/sample - loss: 0.4463 - accuracy: 0.9038\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 87us/sample - loss: 0.4433 - accuracy: 0.9003\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 74us/sample - loss: 0.4395 - accuracy: 0.9003\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 66us/sample - loss: 0.4370 - accuracy: 0.9038\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 67us/sample - loss: 0.4330 - accuracy: 0.9003\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 60us/sample - loss: 0.4305 - accuracy: 0.9038\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 69us/sample - loss: 0.4272 - accuracy: 0.9003\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 78us/sample - loss: 0.4242 - accuracy: 0.9038\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 62us/sample - loss: 0.4222 - accuracy: 0.9072\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 64us/sample - loss: 0.4193 - accuracy: 0.8969\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 64us/sample - loss: 0.4165 - accuracy: 0.9038\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 66us/sample - loss: 0.4134 - accuracy: 0.9038\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 63us/sample - loss: 0.4110 - accuracy: 0.9038\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 62us/sample - loss: 0.4084 - accuracy: 0.9038\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 62us/sample - loss: 0.4065 - accuracy: 0.9072\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 59us/sample - loss: 0.4048 - accuracy: 0.9072\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 58us/sample - loss: 0.4011 - accuracy: 0.9038\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 61us/sample - loss: 0.3991 - accuracy: 0.9072\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 62us/sample - loss: 0.3970 - accuracy: 0.9072\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 62us/sample - loss: 0.3965 - accuracy: 0.9072\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 64us/sample - loss: 0.3931 - accuracy: 0.9107\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 62us/sample - loss: 0.3913 - accuracy: 0.9072\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 61us/sample - loss: 0.3887 - accuracy: 0.9072\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 62us/sample - loss: 0.3868 - accuracy: 0.9072\n",
      "Epoch 77/100\n",
      "291/291 [==============================] - 0s 61us/sample - loss: 0.3846 - accuracy: 0.9107\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 59us/sample - loss: 0.3839 - accuracy: 0.9072\n",
      "Epoch 79/100\n",
      "291/291 [==============================] - 0s 61us/sample - loss: 0.3817 - accuracy: 0.9072\n",
      "Epoch 80/100\n",
      "291/291 [==============================] - 0s 57us/sample - loss: 0.3800 - accuracy: 0.9107\n",
      "Epoch 81/100\n",
      "291/291 [==============================] - 0s 58us/sample - loss: 0.3769 - accuracy: 0.9107\n",
      "Epoch 82/100\n",
      "291/291 [==============================] - 0s 60us/sample - loss: 0.3757 - accuracy: 0.9107\n",
      "Epoch 83/100\n",
      "291/291 [==============================] - 0s 59us/sample - loss: 0.3740 - accuracy: 0.9072\n",
      "Epoch 84/100\n",
      "291/291 [==============================] - 0s 61us/sample - loss: 0.3724 - accuracy: 0.9107\n",
      "Epoch 85/100\n",
      "291/291 [==============================] - 0s 61us/sample - loss: 0.3698 - accuracy: 0.9107\n",
      "Epoch 86/100\n",
      "291/291 [==============================] - 0s 63us/sample - loss: 0.3694 - accuracy: 0.9107\n",
      "Epoch 87/100\n",
      "291/291 [==============================] - 0s 60us/sample - loss: 0.3665 - accuracy: 0.9072\n",
      "Epoch 88/100\n",
      "291/291 [==============================] - 0s 59us/sample - loss: 0.3652 - accuracy: 0.9072\n",
      "Epoch 89/100\n",
      "291/291 [==============================] - 0s 61us/sample - loss: 0.3633 - accuracy: 0.9072\n",
      "Epoch 90/100\n",
      "291/291 [==============================] - 0s 56us/sample - loss: 0.3616 - accuracy: 0.9072\n",
      "Epoch 91/100\n",
      "291/291 [==============================] - 0s 57us/sample - loss: 0.3601 - accuracy: 0.9107\n",
      "Epoch 92/100\n",
      "291/291 [==============================] - 0s 56us/sample - loss: 0.3589 - accuracy: 0.9107\n",
      "Epoch 93/100\n",
      "291/291 [==============================] - 0s 56us/sample - loss: 0.3572 - accuracy: 0.9107\n",
      "Epoch 94/100\n",
      "291/291 [==============================] - 0s 58us/sample - loss: 0.3553 - accuracy: 0.9072\n",
      "Epoch 95/100\n",
      "291/291 [==============================] - 0s 56us/sample - loss: 0.3558 - accuracy: 0.9072\n",
      "Epoch 96/100\n",
      "291/291 [==============================] - 0s 56us/sample - loss: 0.3520 - accuracy: 0.9072\n",
      "Epoch 97/100\n",
      "291/291 [==============================] - 0s 56us/sample - loss: 0.3503 - accuracy: 0.9107\n",
      "Epoch 98/100\n",
      "291/291 [==============================] - 0s 55us/sample - loss: 0.3491 - accuracy: 0.9107\n",
      "Epoch 99/100\n",
      "291/291 [==============================] - 0s 57us/sample - loss: 0.3472 - accuracy: 0.9107\n",
      "Epoch 100/100\n",
      "291/291 [==============================] - 0s 56us/sample - loss: 0.3450 - accuracy: 0.9107\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "id": "bc41d86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/1 - 0s - loss: 0.6702 - accuracy: 0.7260\n",
      "Loss: 0.6525259115924574, Accuracy: 0.7260273694992065\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy= nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "id": "5dab3cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_254\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_836 (Dense)            (None, 8)                 3688      \n",
      "_________________________________________________________________\n",
      "dense_837 (Dense)            (None, 5)                 45        \n",
      "_________________________________________________________________\n",
      "dense_838 (Dense)            (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 3,739\n",
      "Trainable params: 3,739\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Define the model-deep neural net, i.e., the number of input features hidden nodes for each layer\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 8\n",
    "hidden_nodes_layer2 =5\n",
    "# hidden_nodes_layer3 = 1\n",
    "\n",
    "nn= tf.keras.models.Sequential()\n",
    "\n",
    "#First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation =\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "# nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "#Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "#Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "id": "0e75fc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimize=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "id": "ebcf4cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 291 samples\n",
      "Epoch 1/100\n",
      "291/291 [==============================] - 1s 2ms/sample - loss: 0.7569 - accuracy: 0.6151\n",
      "Epoch 2/100\n",
      "291/291 [==============================] - 0s 61us/sample - loss: 0.6827 - accuracy: 0.6564\n",
      "Epoch 3/100\n",
      "291/291 [==============================] - 0s 92us/sample - loss: 0.6354 - accuracy: 0.6873\n",
      "Epoch 4/100\n",
      "291/291 [==============================] - 0s 75us/sample - loss: 0.5965 - accuracy: 0.6907\n",
      "Epoch 5/100\n",
      "291/291 [==============================] - 0s 66us/sample - loss: 0.5611 - accuracy: 0.7045\n",
      "Epoch 6/100\n",
      "291/291 [==============================] - 0s 74us/sample - loss: 0.5319 - accuracy: 0.7045\n",
      "Epoch 7/100\n",
      "291/291 [==============================] - 0s 78us/sample - loss: 0.5043 - accuracy: 0.7320\n",
      "Epoch 8/100\n",
      "291/291 [==============================] - 0s 61us/sample - loss: 0.4802 - accuracy: 0.7320\n",
      "Epoch 9/100\n",
      "291/291 [==============================] - 0s 82us/sample - loss: 0.4544 - accuracy: 0.7491\n",
      "Epoch 10/100\n",
      "291/291 [==============================] - 0s 75us/sample - loss: 0.4312 - accuracy: 0.7732\n",
      "Epoch 11/100\n",
      "291/291 [==============================] - 0s 75us/sample - loss: 0.4078 - accuracy: 0.7766\n",
      "Epoch 12/100\n",
      "291/291 [==============================] - 0s 73us/sample - loss: 0.3862 - accuracy: 0.8007\n",
      "Epoch 13/100\n",
      "291/291 [==============================] - 0s 79us/sample - loss: 0.3662 - accuracy: 0.8179\n",
      "Epoch 14/100\n",
      "291/291 [==============================] - 0s 57us/sample - loss: 0.3469 - accuracy: 0.8282\n",
      "Epoch 15/100\n",
      "291/291 [==============================] - 0s 75us/sample - loss: 0.3290 - accuracy: 0.8522\n",
      "Epoch 16/100\n",
      "291/291 [==============================] - 0s 81us/sample - loss: 0.3127 - accuracy: 0.8797\n",
      "Epoch 17/100\n",
      "291/291 [==============================] - 0s 65us/sample - loss: 0.2954 - accuracy: 0.8866\n",
      "Epoch 18/100\n",
      "291/291 [==============================] - 0s 88us/sample - loss: 0.2801 - accuracy: 0.8900\n",
      "Epoch 19/100\n",
      "291/291 [==============================] - 0s 77us/sample - loss: 0.2663 - accuracy: 0.9038\n",
      "Epoch 20/100\n",
      "291/291 [==============================] - 0s 76us/sample - loss: 0.2526 - accuracy: 0.9072\n",
      "Epoch 21/100\n",
      "291/291 [==============================] - 0s 95us/sample - loss: 0.2407 - accuracy: 0.9072\n",
      "Epoch 22/100\n",
      "291/291 [==============================] - 0s 68us/sample - loss: 0.2285 - accuracy: 0.9107\n",
      "Epoch 23/100\n",
      "291/291 [==============================] - 0s 76us/sample - loss: 0.2174 - accuracy: 0.9141\n",
      "Epoch 24/100\n",
      "291/291 [==============================] - 0s 75us/sample - loss: 0.2064 - accuracy: 0.9175\n",
      "Epoch 25/100\n",
      "291/291 [==============================] - 0s 71us/sample - loss: 0.1965 - accuracy: 0.9278\n",
      "Epoch 26/100\n",
      "291/291 [==============================] - 0s 76us/sample - loss: 0.1865 - accuracy: 0.9347\n",
      "Epoch 27/100\n",
      "291/291 [==============================] - 0s 82us/sample - loss: 0.1783 - accuracy: 0.9381\n",
      "Epoch 28/100\n",
      "291/291 [==============================] - 0s 71us/sample - loss: 0.1694 - accuracy: 0.9381\n",
      "Epoch 29/100\n",
      "291/291 [==============================] - 0s 77us/sample - loss: 0.1619 - accuracy: 0.9416\n",
      "Epoch 30/100\n",
      "291/291 [==============================] - 0s 76us/sample - loss: 0.1539 - accuracy: 0.9450\n",
      "Epoch 31/100\n",
      "291/291 [==============================] - 0s 60us/sample - loss: 0.1477 - accuracy: 0.9450\n",
      "Epoch 32/100\n",
      "291/291 [==============================] - 0s 77us/sample - loss: 0.1416 - accuracy: 0.9519\n",
      "Epoch 33/100\n",
      "291/291 [==============================] - 0s 83us/sample - loss: 0.1366 - accuracy: 0.9553\n",
      "Epoch 34/100\n",
      "291/291 [==============================] - 0s 70us/sample - loss: 0.1321 - accuracy: 0.9553\n",
      "Epoch 35/100\n",
      "291/291 [==============================] - 0s 86us/sample - loss: 0.1267 - accuracy: 0.9553\n",
      "Epoch 36/100\n",
      "291/291 [==============================] - 0s 74us/sample - loss: 0.1232 - accuracy: 0.9588\n",
      "Epoch 37/100\n",
      "291/291 [==============================] - 0s 63us/sample - loss: 0.1184 - accuracy: 0.9656\n",
      "Epoch 38/100\n",
      "291/291 [==============================] - 0s 82us/sample - loss: 0.1159 - accuracy: 0.9622\n",
      "Epoch 39/100\n",
      "291/291 [==============================] - 0s 80us/sample - loss: 0.1120 - accuracy: 0.9656\n",
      "Epoch 40/100\n",
      "291/291 [==============================] - 0s 61us/sample - loss: 0.1094 - accuracy: 0.9656\n",
      "Epoch 41/100\n",
      "291/291 [==============================] - 0s 83us/sample - loss: 0.1072 - accuracy: 0.9656\n",
      "Epoch 42/100\n",
      "291/291 [==============================] - 0s 81us/sample - loss: 0.1059 - accuracy: 0.9656\n",
      "Epoch 43/100\n",
      "291/291 [==============================] - 0s 73us/sample - loss: 0.1028 - accuracy: 0.9691\n",
      "Epoch 44/100\n",
      "291/291 [==============================] - 0s 76us/sample - loss: 0.1011 - accuracy: 0.9691\n",
      "Epoch 45/100\n",
      "291/291 [==============================] - 0s 73us/sample - loss: 0.0990 - accuracy: 0.9656\n",
      "Epoch 46/100\n",
      "291/291 [==============================] - 0s 84us/sample - loss: 0.0982 - accuracy: 0.9656\n",
      "Epoch 47/100\n",
      "291/291 [==============================] - 0s 78us/sample - loss: 0.0959 - accuracy: 0.9691\n",
      "Epoch 48/100\n",
      "291/291 [==============================] - 0s 65us/sample - loss: 0.0948 - accuracy: 0.9656\n",
      "Epoch 49/100\n",
      "291/291 [==============================] - 0s 84us/sample - loss: 0.0926 - accuracy: 0.9656\n",
      "Epoch 50/100\n",
      "291/291 [==============================] - 0s 78us/sample - loss: 0.0923 - accuracy: 0.9691\n",
      "Epoch 51/100\n",
      "291/291 [==============================] - 0s 72us/sample - loss: 0.0891 - accuracy: 0.9691\n",
      "Epoch 52/100\n",
      "291/291 [==============================] - 0s 78us/sample - loss: 0.0882 - accuracy: 0.9691\n",
      "Epoch 53/100\n",
      "291/291 [==============================] - 0s 83us/sample - loss: 0.0860 - accuracy: 0.9759\n",
      "Epoch 54/100\n",
      "291/291 [==============================] - 0s 73us/sample - loss: 0.0856 - accuracy: 0.9656\n",
      "Epoch 55/100\n",
      "291/291 [==============================] - 0s 76us/sample - loss: 0.0839 - accuracy: 0.9691\n",
      "Epoch 56/100\n",
      "291/291 [==============================] - 0s 71us/sample - loss: 0.0835 - accuracy: 0.9725\n",
      "Epoch 57/100\n",
      "291/291 [==============================] - 0s 75us/sample - loss: 0.0813 - accuracy: 0.9725\n",
      "Epoch 58/100\n",
      "291/291 [==============================] - 0s 74us/sample - loss: 0.0799 - accuracy: 0.9759\n",
      "Epoch 59/100\n",
      "291/291 [==============================] - 0s 70us/sample - loss: 0.0781 - accuracy: 0.9794\n",
      "Epoch 60/100\n",
      "291/291 [==============================] - 0s 80us/sample - loss: 0.0788 - accuracy: 0.9691\n",
      "Epoch 61/100\n",
      "291/291 [==============================] - 0s 73us/sample - loss: 0.0760 - accuracy: 0.9794\n",
      "Epoch 62/100\n",
      "291/291 [==============================] - 0s 74us/sample - loss: 0.0753 - accuracy: 0.9725\n",
      "Epoch 63/100\n",
      "291/291 [==============================] - 0s 91us/sample - loss: 0.0737 - accuracy: 0.9759\n",
      "Epoch 64/100\n",
      "291/291 [==============================] - 0s 86us/sample - loss: 0.0725 - accuracy: 0.9759\n",
      "Epoch 65/100\n",
      "291/291 [==============================] - 0s 85us/sample - loss: 0.0723 - accuracy: 0.9794\n",
      "Epoch 66/100\n",
      "291/291 [==============================] - 0s 78us/sample - loss: 0.0716 - accuracy: 0.9759\n",
      "Epoch 67/100\n",
      "291/291 [==============================] - 0s 80us/sample - loss: 0.0712 - accuracy: 0.9794\n",
      "Epoch 68/100\n",
      "291/291 [==============================] - 0s 72us/sample - loss: 0.0699 - accuracy: 0.9794\n",
      "Epoch 69/100\n",
      "291/291 [==============================] - 0s 70us/sample - loss: 0.0686 - accuracy: 0.9828\n",
      "Epoch 70/100\n",
      "291/291 [==============================] - 0s 72us/sample - loss: 0.0665 - accuracy: 0.9828\n",
      "Epoch 71/100\n",
      "291/291 [==============================] - 0s 74us/sample - loss: 0.0675 - accuracy: 0.9828\n",
      "Epoch 72/100\n",
      "291/291 [==============================] - 0s 76us/sample - loss: 0.0662 - accuracy: 0.9828\n",
      "Epoch 73/100\n",
      "291/291 [==============================] - 0s 73us/sample - loss: 0.0656 - accuracy: 0.9828\n",
      "Epoch 74/100\n",
      "291/291 [==============================] - 0s 72us/sample - loss: 0.0644 - accuracy: 0.9759\n",
      "Epoch 75/100\n",
      "291/291 [==============================] - 0s 74us/sample - loss: 0.0647 - accuracy: 0.9794\n",
      "Epoch 76/100\n",
      "291/291 [==============================] - 0s 83us/sample - loss: 0.0629 - accuracy: 0.9828\n",
      "Epoch 77/100\n",
      "291/291 [==============================] - 0s 73us/sample - loss: 0.0621 - accuracy: 0.9794\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 74us/sample - loss: 0.0598 - accuracy: 0.9863\n",
      "Epoch 79/100\n",
      "291/291 [==============================] - 0s 75us/sample - loss: 0.0601 - accuracy: 0.9828\n",
      "Epoch 80/100\n",
      "291/291 [==============================] - 0s 68us/sample - loss: 0.0605 - accuracy: 0.9828\n",
      "Epoch 81/100\n",
      "291/291 [==============================] - 0s 69us/sample - loss: 0.0579 - accuracy: 0.9794\n",
      "Epoch 82/100\n",
      "291/291 [==============================] - 0s 73us/sample - loss: 0.0587 - accuracy: 0.9828\n",
      "Epoch 83/100\n",
      "291/291 [==============================] - 0s 72us/sample - loss: 0.0562 - accuracy: 0.9828\n",
      "Epoch 84/100\n",
      "291/291 [==============================] - 0s 72us/sample - loss: 0.0550 - accuracy: 0.9828\n",
      "Epoch 85/100\n",
      "291/291 [==============================] - 0s 64us/sample - loss: 0.0544 - accuracy: 0.9828\n",
      "Epoch 86/100\n",
      "291/291 [==============================] - 0s 65us/sample - loss: 0.0546 - accuracy: 0.9828\n",
      "Epoch 87/100\n",
      "291/291 [==============================] - 0s 69us/sample - loss: 0.0534 - accuracy: 0.9794\n",
      "Epoch 88/100\n",
      "291/291 [==============================] - 0s 68us/sample - loss: 0.0546 - accuracy: 0.9828\n",
      "Epoch 89/100\n",
      "291/291 [==============================] - 0s 70us/sample - loss: 0.0533 - accuracy: 0.9828\n",
      "Epoch 90/100\n",
      "291/291 [==============================] - 0s 69us/sample - loss: 0.0528 - accuracy: 0.9828\n",
      "Epoch 91/100\n",
      "291/291 [==============================] - 0s 69us/sample - loss: 0.0525 - accuracy: 0.9828\n",
      "Epoch 92/100\n",
      "291/291 [==============================] - 0s 70us/sample - loss: 0.0512 - accuracy: 0.9828\n",
      "Epoch 93/100\n",
      "291/291 [==============================] - 0s 70us/sample - loss: 0.0509 - accuracy: 0.9794\n",
      "Epoch 94/100\n",
      "291/291 [==============================] - 0s 68us/sample - loss: 0.0512 - accuracy: 0.9828\n",
      "Epoch 95/100\n",
      "291/291 [==============================] - 0s 71us/sample - loss: 0.0498 - accuracy: 0.9828\n",
      "Epoch 96/100\n",
      "291/291 [==============================] - 0s 72us/sample - loss: 0.0485 - accuracy: 0.9863\n",
      "Epoch 97/100\n",
      "291/291 [==============================] - 0s 71us/sample - loss: 0.0480 - accuracy: 0.9863\n",
      "Epoch 98/100\n",
      "291/291 [==============================] - 0s 66us/sample - loss: 0.0472 - accuracy: 0.9863\n",
      "Epoch 99/100\n",
      "291/291 [==============================] - 0s 96us/sample - loss: 0.0471 - accuracy: 0.9863\n",
      "Epoch 100/100\n",
      "291/291 [==============================] - 0s 70us/sample - loss: 0.0467 - accuracy: 0.9863\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "id": "17063f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/1 - 0s - loss: 1.4459 - accuracy: 0.7808\n",
      "Loss: 1.002980354714067, Accuracy: 0.7808219194412231\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy= nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "id": "a725ebbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_268\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_878 (Dense)            (None, 8)                 3688      \n",
      "_________________________________________________________________\n",
      "dense_879 (Dense)            (None, 2)                 18        \n",
      "_________________________________________________________________\n",
      "dense_880 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 3,709\n",
      "Trainable params: 3,709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Define the model-deep neural net, i.e., the number of input features hidden nodes for each layer\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 8\n",
    "hidden_nodes_layer2 =2\n",
    "# hidden_nodes_layer3 = 1\n",
    "\n",
    "nn= tf.keras.models.Sequential()\n",
    "\n",
    "#First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation =\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "# nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "#Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "#Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1109,
   "id": "0b494238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimize=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "id": "aaa1cb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 291 samples\n",
      "Epoch 1/120\n",
      "291/291 [==============================] - 1s 2ms/sample - loss: 0.8913 - accuracy: 0.4777\n",
      "Epoch 2/120\n",
      "291/291 [==============================] - 0s 60us/sample - loss: 0.7514 - accuracy: 0.6289\n",
      "Epoch 3/120\n",
      "291/291 [==============================] - 0s 64us/sample - loss: 0.7045 - accuracy: 0.6598\n",
      "Epoch 4/120\n",
      "291/291 [==============================] - 0s 88us/sample - loss: 0.6742 - accuracy: 0.6976\n",
      "Epoch 5/120\n",
      "291/291 [==============================] - 0s 74us/sample - loss: 0.6495 - accuracy: 0.7320\n",
      "Epoch 6/120\n",
      "291/291 [==============================] - 0s 69us/sample - loss: 0.6274 - accuracy: 0.7595\n",
      "Epoch 7/120\n",
      "291/291 [==============================] - 0s 77us/sample - loss: 0.6073 - accuracy: 0.7663\n",
      "Epoch 8/120\n",
      "291/291 [==============================] - 0s 75us/sample - loss: 0.5894 - accuracy: 0.7801\n",
      "Epoch 9/120\n",
      "291/291 [==============================] - 0s 69us/sample - loss: 0.5733 - accuracy: 0.7869\n",
      "Epoch 10/120\n",
      "291/291 [==============================] - 0s 81us/sample - loss: 0.5562 - accuracy: 0.8007\n",
      "Epoch 11/120\n",
      "291/291 [==============================] - 0s 86us/sample - loss: 0.5415 - accuracy: 0.8041\n",
      "Epoch 12/120\n",
      "291/291 [==============================] - 0s 69us/sample - loss: 0.5257 - accuracy: 0.8144\n",
      "Epoch 13/120\n",
      "291/291 [==============================] - 0s 78us/sample - loss: 0.5105 - accuracy: 0.8213\n",
      "Epoch 14/120\n",
      "291/291 [==============================] - 0s 77us/sample - loss: 0.4966 - accuracy: 0.8282\n",
      "Epoch 15/120\n",
      "291/291 [==============================] - 0s 82us/sample - loss: 0.4818 - accuracy: 0.8351\n",
      "Epoch 16/120\n",
      "291/291 [==============================] - 0s 79us/sample - loss: 0.4687 - accuracy: 0.8316\n",
      "Epoch 17/120\n",
      "291/291 [==============================] - 0s 76us/sample - loss: 0.4549 - accuracy: 0.8351\n",
      "Epoch 18/120\n",
      "291/291 [==============================] - 0s 85us/sample - loss: 0.4415 - accuracy: 0.8316\n",
      "Epoch 19/120\n",
      "291/291 [==============================] - 0s 67us/sample - loss: 0.4280 - accuracy: 0.8454\n",
      "Epoch 20/120\n",
      "291/291 [==============================] - 0s 82us/sample - loss: 0.4154 - accuracy: 0.8488\n",
      "Epoch 21/120\n",
      "291/291 [==============================] - 0s 77us/sample - loss: 0.4033 - accuracy: 0.8522\n",
      "Epoch 22/120\n",
      "291/291 [==============================] - 0s 70us/sample - loss: 0.3932 - accuracy: 0.8557\n",
      "Epoch 23/120\n",
      "291/291 [==============================] - 0s 76us/sample - loss: 0.3826 - accuracy: 0.8557\n",
      "Epoch 24/120\n",
      "291/291 [==============================] - 0s 76us/sample - loss: 0.3730 - accuracy: 0.8557\n",
      "Epoch 25/120\n",
      "291/291 [==============================] - 0s 84us/sample - loss: 0.3634 - accuracy: 0.8591\n",
      "Epoch 26/120\n",
      "291/291 [==============================] - 0s 76us/sample - loss: 0.3539 - accuracy: 0.8591\n",
      "Epoch 27/120\n",
      "291/291 [==============================] - 0s 69us/sample - loss: 0.3457 - accuracy: 0.8591\n",
      "Epoch 28/120\n",
      "291/291 [==============================] - 0s 80us/sample - loss: 0.3382 - accuracy: 0.8591\n",
      "Epoch 29/120\n",
      "291/291 [==============================] - 0s 78us/sample - loss: 0.3301 - accuracy: 0.8591\n",
      "Epoch 30/120\n",
      "291/291 [==============================] - 0s 81us/sample - loss: 0.3252 - accuracy: 0.8591\n",
      "Epoch 31/120\n",
      "291/291 [==============================] - 0s 87us/sample - loss: 0.3167 - accuracy: 0.8591\n",
      "Epoch 32/120\n",
      "291/291 [==============================] - 0s 76us/sample - loss: 0.3102 - accuracy: 0.8591\n",
      "Epoch 33/120\n",
      "291/291 [==============================] - 0s 83us/sample - loss: 0.3057 - accuracy: 0.8591\n",
      "Epoch 34/120\n",
      "291/291 [==============================] - 0s 79us/sample - loss: 0.2993 - accuracy: 0.8591\n",
      "Epoch 35/120\n",
      "291/291 [==============================] - 0s 73us/sample - loss: 0.2951 - accuracy: 0.8591\n",
      "Epoch 36/120\n",
      "291/291 [==============================] - 0s 78us/sample - loss: 0.2883 - accuracy: 0.8625\n",
      "Epoch 37/120\n",
      "291/291 [==============================] - 0s 75us/sample - loss: 0.2829 - accuracy: 0.8625\n",
      "Epoch 38/120\n",
      "291/291 [==============================] - 0s 85us/sample - loss: 0.2781 - accuracy: 0.8625\n",
      "Epoch 39/120\n",
      "291/291 [==============================] - 0s 91us/sample - loss: 0.2737 - accuracy: 0.8625\n",
      "Epoch 40/120\n",
      "291/291 [==============================] - 0s 105us/sample - loss: 0.2705 - accuracy: 0.8625\n",
      "Epoch 41/120\n",
      "291/291 [==============================] - 0s 81us/sample - loss: 0.2662 - accuracy: 0.8625\n",
      "Epoch 42/120\n",
      "291/291 [==============================] - 0s 86us/sample - loss: 0.2624 - accuracy: 0.8625\n",
      "Epoch 43/120\n",
      "291/291 [==============================] - 0s 88us/sample - loss: 0.2590 - accuracy: 0.8660\n",
      "Epoch 44/120\n",
      "291/291 [==============================] - 0s 82us/sample - loss: 0.2549 - accuracy: 0.8660\n",
      "Epoch 45/120\n",
      "291/291 [==============================] - 0s 85us/sample - loss: 0.2524 - accuracy: 0.8660\n",
      "Epoch 46/120\n",
      "291/291 [==============================] - 0s 73us/sample - loss: 0.2498 - accuracy: 0.8660\n",
      "Epoch 47/120\n",
      "291/291 [==============================] - 0s 67us/sample - loss: 0.2462 - accuracy: 0.8660\n",
      "Epoch 48/120\n",
      "291/291 [==============================] - 0s 92us/sample - loss: 0.2434 - accuracy: 0.8660\n",
      "Epoch 49/120\n",
      "291/291 [==============================] - 0s 63us/sample - loss: 0.2417 - accuracy: 0.8660\n",
      "Epoch 50/120\n",
      "291/291 [==============================] - 0s 80us/sample - loss: 0.2389 - accuracy: 0.8660\n",
      "Epoch 51/120\n",
      "291/291 [==============================] - 0s 79us/sample - loss: 0.2368 - accuracy: 0.8660\n",
      "Epoch 52/120\n",
      "291/291 [==============================] - 0s 64us/sample - loss: 0.2346 - accuracy: 0.8660\n",
      "Epoch 53/120\n",
      "291/291 [==============================] - 0s 85us/sample - loss: 0.2334 - accuracy: 0.8660\n",
      "Epoch 54/120\n",
      "291/291 [==============================] - 0s 81us/sample - loss: 0.2309 - accuracy: 0.8660\n",
      "Epoch 55/120\n",
      "291/291 [==============================] - 0s 74us/sample - loss: 0.2286 - accuracy: 0.8660\n",
      "Epoch 56/120\n",
      "291/291 [==============================] - 0s 77us/sample - loss: 0.2268 - accuracy: 0.8660\n",
      "Epoch 57/120\n",
      "291/291 [==============================] - 0s 80us/sample - loss: 0.2255 - accuracy: 0.8694\n",
      "Epoch 58/120\n",
      "291/291 [==============================] - 0s 76us/sample - loss: 0.2233 - accuracy: 0.8694\n",
      "Epoch 59/120\n",
      "291/291 [==============================] - 0s 74us/sample - loss: 0.2219 - accuracy: 0.8694\n",
      "Epoch 60/120\n",
      "291/291 [==============================] - 0s 78us/sample - loss: 0.2198 - accuracy: 0.8729\n",
      "Epoch 61/120\n",
      "291/291 [==============================] - 0s 85us/sample - loss: 0.2192 - accuracy: 0.8763\n",
      "Epoch 62/120\n",
      "291/291 [==============================] - 0s 85us/sample - loss: 0.2171 - accuracy: 0.8797\n",
      "Epoch 63/120\n",
      "291/291 [==============================] - 0s 82us/sample - loss: 0.2159 - accuracy: 0.8797\n",
      "Epoch 64/120\n",
      "291/291 [==============================] - 0s 76us/sample - loss: 0.2135 - accuracy: 0.8832\n",
      "Epoch 65/120\n",
      "291/291 [==============================] - 0s 73us/sample - loss: 0.2141 - accuracy: 0.8797\n",
      "Epoch 66/120\n",
      "291/291 [==============================] - 0s 73us/sample - loss: 0.2112 - accuracy: 0.8797\n",
      "Epoch 67/120\n",
      "291/291 [==============================] - 0s 73us/sample - loss: 0.2102 - accuracy: 0.8797\n",
      "Epoch 68/120\n",
      "291/291 [==============================] - 0s 71us/sample - loss: 0.2083 - accuracy: 0.8797\n",
      "Epoch 69/120\n",
      "291/291 [==============================] - 0s 76us/sample - loss: 0.2062 - accuracy: 0.8797\n",
      "Epoch 70/120\n",
      "291/291 [==============================] - 0s 76us/sample - loss: 0.2058 - accuracy: 0.8797\n",
      "Epoch 71/120\n",
      "291/291 [==============================] - 0s 68us/sample - loss: 0.2042 - accuracy: 0.8797\n",
      "Epoch 72/120\n",
      "291/291 [==============================] - 0s 74us/sample - loss: 0.2020 - accuracy: 0.8832\n",
      "Epoch 73/120\n",
      "291/291 [==============================] - 0s 94us/sample - loss: 0.2014 - accuracy: 0.8797\n",
      "Epoch 74/120\n",
      "291/291 [==============================] - 0s 82us/sample - loss: 0.2004 - accuracy: 0.8832\n",
      "Epoch 75/120\n",
      "291/291 [==============================] - 0s 69us/sample - loss: 0.1990 - accuracy: 0.8832\n",
      "Epoch 76/120\n",
      "291/291 [==============================] - 0s 70us/sample - loss: 0.1976 - accuracy: 0.8797\n",
      "Epoch 77/120\n",
      "291/291 [==============================] - 0s 75us/sample - loss: 0.1971 - accuracy: 0.8832\n",
      "Epoch 78/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 83us/sample - loss: 0.1965 - accuracy: 0.8832\n",
      "Epoch 79/120\n",
      "291/291 [==============================] - 0s 71us/sample - loss: 0.1960 - accuracy: 0.8866\n",
      "Epoch 80/120\n",
      "291/291 [==============================] - 0s 68us/sample - loss: 0.1932 - accuracy: 0.8866\n",
      "Epoch 81/120\n",
      "291/291 [==============================] - 0s 66us/sample - loss: 0.1931 - accuracy: 0.8797\n",
      "Epoch 82/120\n",
      "291/291 [==============================] - 0s 70us/sample - loss: 0.1921 - accuracy: 0.8832\n",
      "Epoch 83/120\n",
      "291/291 [==============================] - 0s 76us/sample - loss: 0.1908 - accuracy: 0.8866\n",
      "Epoch 84/120\n",
      "291/291 [==============================] - 0s 67us/sample - loss: 0.1902 - accuracy: 0.8832\n",
      "Epoch 85/120\n",
      "291/291 [==============================] - 0s 71us/sample - loss: 0.1885 - accuracy: 0.8866\n",
      "Epoch 86/120\n",
      "291/291 [==============================] - 0s 66us/sample - loss: 0.1867 - accuracy: 0.8900\n",
      "Epoch 87/120\n",
      "291/291 [==============================] - 0s 68us/sample - loss: 0.1850 - accuracy: 0.8935\n",
      "Epoch 88/120\n",
      "291/291 [==============================] - 0s 68us/sample - loss: 0.1846 - accuracy: 0.8935\n",
      "Epoch 89/120\n",
      "291/291 [==============================] - 0s 81us/sample - loss: 0.1836 - accuracy: 0.8969\n",
      "Epoch 90/120\n",
      "291/291 [==============================] - 0s 64us/sample - loss: 0.1825 - accuracy: 0.8935\n",
      "Epoch 91/120\n",
      "291/291 [==============================] - 0s 71us/sample - loss: 0.1813 - accuracy: 0.8935\n",
      "Epoch 92/120\n",
      "291/291 [==============================] - 0s 99us/sample - loss: 0.1796 - accuracy: 0.8935\n",
      "Epoch 93/120\n",
      "291/291 [==============================] - 0s 74us/sample - loss: 0.1797 - accuracy: 0.8969\n",
      "Epoch 94/120\n",
      "291/291 [==============================] - 0s 70us/sample - loss: 0.1784 - accuracy: 0.8969\n",
      "Epoch 95/120\n",
      "291/291 [==============================] - 0s 71us/sample - loss: 0.1769 - accuracy: 0.9003\n",
      "Epoch 96/120\n",
      "291/291 [==============================] - 0s 73us/sample - loss: 0.1766 - accuracy: 0.9003\n",
      "Epoch 97/120\n",
      "291/291 [==============================] - 0s 73us/sample - loss: 0.1764 - accuracy: 0.8969\n",
      "Epoch 98/120\n",
      "291/291 [==============================] - 0s 69us/sample - loss: 0.1758 - accuracy: 0.9003\n",
      "Epoch 99/120\n",
      "291/291 [==============================] - 0s 75us/sample - loss: 0.1745 - accuracy: 0.9003\n",
      "Epoch 100/120\n",
      "291/291 [==============================] - 0s 75us/sample - loss: 0.1744 - accuracy: 0.9003\n",
      "Epoch 101/120\n",
      "291/291 [==============================] - 0s 69us/sample - loss: 0.1739 - accuracy: 0.8969\n",
      "Epoch 102/120\n",
      "291/291 [==============================] - 0s 65us/sample - loss: 0.1734 - accuracy: 0.9003\n",
      "Epoch 103/120\n",
      "291/291 [==============================] - 0s 66us/sample - loss: 0.1722 - accuracy: 0.9003\n",
      "Epoch 104/120\n",
      "291/291 [==============================] - 0s 73us/sample - loss: 0.1712 - accuracy: 0.9003\n",
      "Epoch 105/120\n",
      "291/291 [==============================] - 0s 69us/sample - loss: 0.1716 - accuracy: 0.8969\n",
      "Epoch 106/120\n",
      "291/291 [==============================] - 0s 72us/sample - loss: 0.1703 - accuracy: 0.9003\n",
      "Epoch 107/120\n",
      "291/291 [==============================] - 0s 66us/sample - loss: 0.1707 - accuracy: 0.8969\n",
      "Epoch 108/120\n",
      "291/291 [==============================] - 0s 72us/sample - loss: 0.1691 - accuracy: 0.9003\n",
      "Epoch 109/120\n",
      "291/291 [==============================] - 0s 69us/sample - loss: 0.1688 - accuracy: 0.9003\n",
      "Epoch 110/120\n",
      "291/291 [==============================] - 0s 75us/sample - loss: 0.1683 - accuracy: 0.8969\n",
      "Epoch 111/120\n",
      "291/291 [==============================] - 0s 66us/sample - loss: 0.1670 - accuracy: 0.9003\n",
      "Epoch 112/120\n",
      "291/291 [==============================] - 0s 70us/sample - loss: 0.1669 - accuracy: 0.9003\n",
      "Epoch 113/120\n",
      "291/291 [==============================] - 0s 69us/sample - loss: 0.1660 - accuracy: 0.9003\n",
      "Epoch 114/120\n",
      "291/291 [==============================] - 0s 75us/sample - loss: 0.1651 - accuracy: 0.9003\n",
      "Epoch 115/120\n",
      "291/291 [==============================] - 0s 66us/sample - loss: 0.1640 - accuracy: 0.9003\n",
      "Epoch 116/120\n",
      "291/291 [==============================] - 0s 71us/sample - loss: 0.1626 - accuracy: 0.9003\n",
      "Epoch 117/120\n",
      "291/291 [==============================] - 0s 74us/sample - loss: 0.1625 - accuracy: 0.9038\n",
      "Epoch 118/120\n",
      "291/291 [==============================] - 0s 72us/sample - loss: 0.1619 - accuracy: 0.9003\n",
      "Epoch 119/120\n",
      "291/291 [==============================] - 0s 68us/sample - loss: 0.1613 - accuracy: 0.9038\n",
      "Epoch 120/120\n",
      "291/291 [==============================] - 0s 72us/sample - loss: 0.1606 - accuracy: 0.9038\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=(120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1111,
   "id": "6778bf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/1 - 0s - loss: 1.1899 - accuracy: 0.6712\n",
      "Loss: 1.243360643517481, Accuracy: 0.6712328791618347\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy= nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a177a888",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
